---
title: "Bio720 R In Class Exercise 2"
author: "Ian Dworkin"
date: "October 29, 2018"
---

In class assignment. Please work in groups of 2-3. When you are finished with your assignment, please (as both a .Rmd and a .md file) add this to your class github repo (or make a new one if you really want).

## for loops and the apply family of functions
During the past two week for, you learned a bit about how to use `for` loops and `apply` family of functions. Now we are going to do some in class practice and extend your understanding of how they work. In case you want some alternative tutorials [here](https://www.datacamp.com/community/tutorials/tutorial-on-loops-in-r#gs.FgFVHlY) is one that goes into more detail.

1. What happens to `x` for each of these functions after you run them? Please explain what is happening in each case. i.e. Why do these behave differently?

```{r}
x <- 1

for (i in 1:9) {
    x <- x + 1
    print(x)
}

x

```

**VS**

```{r, error=TRUE}
rm(x)

countFun <-function(x)
{

  for (i in 1:10) {
    x <- x + 1
    print(x)
}}

countFun(1)
x
```

Why do these behave differently?


These behave differently because in one case we have assigned a value to the variable `x` in the global environment, while in the second example the variable is assigned within the context of the `countFun` function. This is because the assignment happened within the context of the function. The details of how this work can get complicated, and different programming languages handle it differently. For more information you should look up a bit about *lexical scoping* and the idea of *environments* in `R`. What is important though is that unless you specifically ask for a variable to be returned from a function, *What happens in a function, stays in the function* for `R`. There are a few exceptions, but keep this in mind generally. This [tutorial](https://darrenjw.wordpress.com/2011/11/23/lexical-scope-and-function-closures-in-r/) might give you some more ideas.


2. Write a for loop that generates a vector which is the square of all integers from 1 to 10000. Make this all happen within the loop. i.e. We are going to use the `system.time()` function to monitor how long it takes. This is pretty course, and a way better way of doing this is with the `microbenchmark` package.



```{r}
# initialize a vector of length 1
x <- NA

#system.time( YOUR FOR LOOP HERE)

system.time( 
    for (i in 1:10000) {x[i] <- i^2})
```

3.  Now do the same thing but *pre-allocate* memory for the vector `x` to store the 10000 values *before* running the `for` loop. You don't need to do anything differently, just initialize a vector of length 10000.

```{r}
# initialize a vector of length 10000
rm(x)
x <- rep(NA, 10000)

#system.time( YOUR FOR LOOP HERE)

system.time( for (i in 1:10000) {x[i] <- i^2})
```

Which runs faster? Please explain why?

When we pre-allocate memory for the vector that we are storing all of our calculations in, R only needs to generate the record of this in its memory once. Then it is essentially filling in the values. In the first example, we are replacing the old version of `x` with the new version, and each time `R` needs to allocate memory to do so.

4. What is a very "`R`" to make this even faster? (i.e. think about vectorization)

```{r}
rm(x)
x <- 1:10000
system.time(x <- x^2)
```

5. Why is this faster?

This is faster because `R` is vectorized, so we have no need to run a for loop. Instead it does the computation (squaring the values) on the vector itself all simulataneously. Behind the scenes, R is likely sending the computation to some very fast code written in a lower level language (either `C` or `fortran`)

So what is the lesson learned from this?

If you can vectorize your computations do so. The code is cleaner and faster. If you need to use a `for` loop, don't forget to pre-allocate the appropriate amount of space for your object, and don't try to "grow" or repeatedly over-write variables if you can avoid it!

6 - Compare and constrast the following pieces of code for both what they are doing, and for speed (you can wrap this in `system.time()`). We are using the `rnorm` function which generates random numbers from a normal distribution (with a particular mean and standard deviation)

```{r}
n <- 10000 # just run this once, each time you change n

rm(x)
system.time(x <- replicate(n = n, expr = rnorm(1, mean = 5, sd = 5)))

```

**VS**

```{r}
rm(x)
x <- rep(NA, n)
system.time(for (i in 1:n) x[i] <- rnorm(1, mean = 5, sd = 5))
```

Repeat each of these 5 times, and write down how long they take. Now repeat this for `n = 100000` iterations. Repeat for `n = 1000000`

6. (continued) Is there a difference in speed? Can you explain why? What are these two pieces of code doing differently?

The apply like functions are sort of half way between dynamically growing your object, and pre-allocation. As it has not done a pre-allocation, it does not need to dynamically grow things somewhat. However, it does not do so one value at a time. The take home message is that the apply like family of functions are great to use when you have moderate numbers of calculations to do (upto ~100000 or so), but then they get slower relative to the use of a for loop with pre-allocation.

7. Can you think of a faster way to generate the random numbers? hint, look at the help for `rnorm` and think about what R does really well (generally)

```{r}
rm(x)
system.time(x <- rnorm(n, mean =5 , sd = 5))
```

Again, use the fact that R does its computations in a vectorized fashion to speed everything up!


## Running a power analysis.

In statistics, we often want to check (before doing an experiment) how likely we will be able to detect "an effect". This is true whether we are doing RNAseq, or a simple t-test. A tests statistical power is a function of three things. First, the magnitude of the observed effect (i.e. does your experiment have a big effect on gene expression or really small subtle effects). Second the amount of variation within each treatment group (if what you measure is really noisy, it will make it more difficult to get accurate estimates) and of course sample size. So when statistically oriented researchers are testing new methods, or just planning experiments, they will often use simulations to perform power analyses.  These require repeating the same simulations over and over again and checking results against some expectation or some hypothetical threshold (i.e. statistical significance is something some researchers care about... although you should focus on magnitude of effect size and confidence intervals... but that is another conversation).

Here is an example of a very simple simulation, which generates a linear relationship between two variables (the dependent variable *x* and the response variable *y*), simulates values of *x* based on this relationship and the amount of variation (noise) and then fits a linear regression and extracts the p-value associated with the slope of the relationship.

```{r}
rm(list=ls())

# sample size, n
n <- 20

# intercept, a
a = 3

# slope, b
b = 0.3

# independent/explanatory variable
x <- rnorm( n = n, mean = 10, sd = 2)

# response/dependent variable
y <- rnorm(n = length(x), mean = a + b*x, sd = 1 )

plot(y ~ x, pch = 20, cex = 1.5)

# use the `lm` function to fit a linear model (including   a regression like here)
mod_1 <- lm(y ~ x)

summary(mod_1) # just to look at.

(p_val <- summary(mod_1)$coef[2,4])

```

8 - How would you take this idea and create a vector that stores the p_values from these simulations, and repeat the simulation 1000 times using a `for` loop? Then use this vector to find out what proportion of p-values are less than 0.05.You can finish this code up by using a histogram (with the `hist` function) to look at the distribution of p-values.

```{r}

rm(list=ls())

nsims = 1000

# sample size, n
n <- 20

# intercept, a
a = 3

# slope, b
b = 0.25

pvals <- rep(NA, nsims)

for (p in 1:nsims) {
	x <- rnorm( n = n, mean = 10, sd = 2)
    y <- rnorm(n = length(x), mean = a + b*x, sd = 1 )
    mod_1 <- lm(y ~ x)
    pvals[p] <- summary(mod_1)$coef[2,4]}

# proportion less than 0.05?
sum(pvals < 0.05)/length(pvals) # estimate of the power.

hist(pvals)   
```


9.  How would you do the same thing as in question 9 but by writing an explicit function and using `replicate` instead of a `for` loop?

```{r}
rm(list=ls())
nsims = 1000

pow_sim_1 <- function(a, b, n,  std_dev){
	x <- rnorm( n = n, mean = 10, sd = 2)
    y <- rnorm(n = length(x), mean = a + b*x, sd = std_dev )
    mod_1 <- lm(y ~ x)
    return(summary(mod_1)$coef[2,4])
}

pvals <- replicate(n = nsims, pow_sim_1(a = 3, b = 0.3, n = 20, std_dev =1 ))

length(pvals)
sum(pvals < 0.05)/length(pvals)
hist(pvals)
```

Why are the results from question 8 and 9 not the same?

10 - Say you wanted to see what would happened if you varied the sample size from n = 10 to n = 100 or varied the slope from 0 to 0.5? How would you do this using both approaches from questions 9 and 10 (you may need to use nested for loops).

**Here is a slightly more involved example**

First with a set of nested for loops, one to vary the slope, the next (nested within the first) to vary the sample size and the final for loop (nested with the loop for the sample size) performs the repeated iteration over and over.

```{r}
rm(list=ls())
N = 200  # Number of simulations for inner loop. You generally want this to be >1000.

p = rep(NA, N) # initializing the vector to store the p values in the inner for loop.

#Global Parameter values
a = 3 # intercept
b <- seq(from=0, to=0.5, by=0.05)

sample_size <- seq(from = 10 ,to = 100 ,by = 5)  # Incremently increasing sample size

power.size <- numeric(length(sample_size)) # initializing the vector to store the power at each sample size for the outer for loop.

### initialize the matrix to store all of the power estimates
power.b <- matrix(NA,length(sample_size),length(b))

## Now the actual for loop
system.time(
for (k in 1:length(b))  # across the different values for the slope
 {

  b_b <- b[k]

   for (j in 1:length(sample_size))  # looping through the different sample_sizes

    {

      s_s = sample_size[j]
      for (i in 1:N)
      {
       x <- rnorm(s_s, mean = 10, sd = 2)  # simulate values of predictor
       y_det <- a + b_b*x             # deterministic part of model
       y_sim <- rnorm(s_s, mean = y_det, sd = 2)  # Simulate y|x values
       lm1 <- lm(y_sim ~ x)                    # fit model given simulation
       p[i] <- coef(summary(lm1))[2,4] # You may want to extract a different p-value from the model.

     }

      power.size[j] <- length(p[p<0.05])/N   # How many p-values are less than alpha (0.05)
   }

    power.b[,k] <- power.size
}
)


# Now we graph it.
par(mfrow=c(1,2))

#3D perspective plot
persp(y=b, x=sample_size, z=power.b, col="blue", theta=-65,
    shade=0.75, ltheta=45, ylab="slope", xlab="Sample Size",
    lphi=30, zlim=c(0,1.25), ticktype = "detailed")

# contour plot
contour(z=power.b, x=sample_size, y=b, col="blue",  ylab="slope", xlab="Sample Size")

#fancy contour
filled.contour(z=power.b, x=sample_size, y=b,
    ylim=c(min(b),max(b)), xlim=c(min(sample_size), max(sample_size)),
    xlab="Sample Size", ylab="slope", color = topo.colors)
```


### How about in a more `R` like fashion?

We could have used replicate instead of the most internal for loop, which would have made this look less messy. However, the `R` way uses some new approaches based on the apply like family. In particular a function, `expand.grid` which helps us make all possible combinations of two vectors.

```{r}
expand.grid(letters[1:5], 10:6)
```

We will use this in combination with one of the apply functions `mapply()`

```{r}
#Global Parameter values
a = 3 # intercept
b <- seq(from = 0, to = 0.5, by = 0.05) # values for the slope

std_dev = 2
sample_size <- seq(from = 10, to = 100, by = 5)


# use expand grid to get all combinations of b (slope) and sample_size
b_N <- expand.grid(b, sample_size)  # may be worth looking at b_N to see what is being stored.
dim(b_N)
colnames(b_N) <- c("b", "sample_size")

# Here is the function to generate the simulation and fit the model given the simulated data.
SimulatePower <- function(sample_size, b_b, a, std_dev){
	x <- rnorm(sample_size, mean = 10 , sd = 2)
	y_det <- a + b_b*x
    y_sim <- rnorm(sample_size, mean = y_det, sd = std_dev)
    lm1 <- lm(y_sim~x)
    pval <- coef(summary(lm1))[2,4]}

# We can use this for one sample_size and slope
check_it_works <- replicate(1000, SimulatePower(sample_size = 15, b_b = 0, a = 3, std_dev = 2))

hist(check_it_works, freq=T)

```

The basic approach works like this. This goes through all combinations of `sample_size` and `b` (in `b_N`) and runs the `SimulationPower()`.


```{r}
p_values <- mapply(SimulatePower,
    sample_size  = b_N$sample_size, b_b = b_N$b,
    MoreArgs=list(a = 3, std_dev = 2))
```

How ever, this only runs through the whole set of parameters (slopes and sample sizes) once. So we need to place this function within the context of a replicate function.

```{r}
system.time(
rep_p <- replicate(n = 200, mapply(SimulatePower,
    sample_size  = b_N$sample_size, b_b = b_N$b, # arguments to vectorize across
    MoreArgs=list(a=0, std_dev=1)) )   # other parameters
)
```

Each row represents a distinct combination of sample size and slope. Each column an iteration of that simulation.

```{r}
dim(rep_p)
```

Now we can compute the power. We use the apply function to determine the fraction of p-values less than 0.05 across rows.

```{r}
power_lev <- apply(rep_p, MARGIN=1,
    function(x) length(x[x <= 0.05])/length(x)) # how many p-values are less than 0.05
```

The only problem with this approach is that you need to make the matrix of p-values, which are otherwise just stored as a single vector.

```{r}
grid_matrix <- matrix(data=power_lev, nrow=length(b), ncol=length(sample_size))
```

Now we can plot it like before.

```{r}
persp(x=b ,y=sample_size, z=grid_matrix, col="blue",
    theta=-10, shade=0.75, phi=15, d=2, r=0.1,
    xlab="slope", ylab="sample size", zlab="power",
    ticktype="detailed")

filled.contour(z=grid_matrix, y=sample_size, x=b,
    xlim=c(min(b),max(b)), ylim=c(min(sample_size), max(sample_size)),
    ylab="Sample Size", xlab="slope", color = topo.colors)
```
