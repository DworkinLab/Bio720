---
title: "Bio720 - Simulating Data"
author: "Ian Dworkin"
date: "11/19/2018"
output:
  slidy_presentation:
    incremental: yes
  ioslides_presentation:
    incremental: yes
    keep_md: yes
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Slide 1

One of the most important skills in your bag as new computational biologists is the ability to perform simulations. In particular, to simulate data or evaluate models numerically (or both).

## Slide 2
In biology mathematical models are the basis for much of the theoretical and conceptual background in disciplines like ecology, evolution, population genetics, molecular evolution & biochemistry.

## Slide 3

Many of the models that are developed are not *analytically* tractable. That is, without making very strong biological assumptions there are no *closed form solutions*.

That is the models can not be solved for the general case.

## Using computers to find numerical solutions

- For such models, "solutions" can still be found.
- For some models, stability analysis can be performed (among other techniques).
- However, most often, scientists resort to computers to identify *numerical solutions*

## Deterministic VS. Stochastic
- Within *dynamical* models, that include the majority of models in biology there are two broad categories.
- **Deterministic** - where the outcome of the model entirely depends on the model itself and the starting conditions.
- **Stochastic** - where random events influence the outcomes of the model, and only the probability of events can be predicted, not exact outcomes.

## A simple deterministic model one-locus model of natural selection.
- In population genetics we often start with a simple deterministic model of how selection on an allele influences its frequency in the population over time.
- In a simple haploid model we can envision two alternative alleles, *A* and *a*.
- *a* is initially fixed in the population, but the new mutation *A* arrives and it is beneficial. What will happen to this allele?

## Haploid selection model
- Frequency of *A* at time *t* is $p(t)$
- Fitness of *A* is $W_A$, and for *a* is $W_a$

$p(t+1) = \frac{p(t) W_A}{p(t) W_A + W_a(1-p(t))}$

$p(t+1) = \frac{p(t) W_A} {\overline W }$

- Where $\overline{W}$ is mean fitness for the population

- How would you convert this into *R* code for one generation to the next?

- Start with what variables you need.

## Converting this into R code - What variables
- We need variables for the fitness values for each allele, $W_A$, $W_a$ and for allele frequency of A $p(t+1)$ at time t and t+1.

- With this we can write the equation for allele frequency change from one generation to the next.

## Converting this into R code - What variables
```{r echo=TRUE}
p_t1 <- function(w_A, w_a, p_t0) {
        w_bar <- (p_t0*w_A) + ((1-p_t0)*w_a) # mean pop fitness
		p_t1 <- (w_A*p_t0)/w_bar
        return(p_t1)}

p_t1(w_A = 1.1, w_a = 1.0, p_t0 = 0.5)
```

## Is this deterministic or stochastic, what would be a quick way to check?

## Is this deterministic or stochastic, what would be a quick way to check?
```{r echo=TRUE}
replicate(n = 100, p_t1(1.1, 1.0, 0.5))
```

## Allele frequency dynamics.
- Now let's extend this across many generations. We need to rewrite the function as we expect the allele frequencies to change each generation. Also, mean population fitness will change each generation (as allele frequency changes)

- write this simulation (a *for loop* would be sensible) and go for 200 generations, and look at the dynamics (starting allele frequency is p = 0.01). Wrap it all as a function called `haploid_selection`

## 

```{r echo=TRUE}
haploid_selection <- function(p0 = 0.01, w1 = 1, w2 = 0.9, n = 100) {
    
    # Initialize vectors to store allele frequencies and mean pop fitness
    p <- rep(NA,n)  # a vector to store allele frequencies
    
    w_bar <- rep(NA, n)
     
    # starting conditions
   	p[1] <- p0 # starting allele frequencies

	w_bar[1] <- (p[1]*w1) + ((1-p[1])*w2)
	
	# now we need to loop from generation to generation
	for ( i in 2:n) {
		w_bar[i - 1] <- (p[i - 1]*w1) + ((1-p[i - 1])*w2) # mean population fitness
		p[i] <- (w1*p[i - 1])/w_bar[i - 1]
	}
    
    return(p)
}

```
## Test the model and plot it.

```{r echo=TRUE}
p <- haploid_selection()
generations <- 1:length(p)
plot(p ~ generations, pch = 20, 
     ylab = "allele frequency", 
     xlab = "generation")
```

## Using simple numerical simulation to gain intuition for the system.

- Try altering fitness advantage of *A* a little bit. Or reducing initial allele frequency
- Is this deterministic or stochastic?

## Making a more general function


```{r, echo = TRUE}
haploid.selection <- function(p0 = 0.01, w1 = 1, w2 = 0.9, n = 100) {
    
# Initialize vectors to store p, delta p and mean pop fitness
    
p <- rep(NA,n) 
    
delta_p <- rep(NA, n) 
	
w_bar <- rep(NA, n)
     
# starting conditions
p[1] <- p0 # starting allele frequencies

delta_p[1] <- 0 #change in allele frequency
	
w_bar[1] <- (p[1]*w1) + ((1-p[1])*w2)
	
# now we need to loop from generation to generation
for ( i in 2:n) {
    w_bar[i - 1] <- (p[i - 1]*w1) + ((1-p[i - 1])*w2)
		p[i] <- (w1*p[i - 1])/w_bar[i - 1]
		delta_p[i] <- p[i] - p[i-1] 
	}
    
    if (any(p > 0.9999)) {
    fixation <- min(which.max(p > 0.9999))
    cat("fixation for A1 occurs approximately at generation:", fixation )	
    } else {
        maxAlleleFreq <- max(p)
    	cat("fixation of A1 does not occur, max. allele frequency is:", print(maxAlleleFreq, digits = 2) )
    }
    
# Let's make some plots
par(mfrow=c(2,2))
    
# 1. mean population fitness over time
plot(x = 1:n, y = w_bar, 
     xlab = "generations", 
     ylab = expression(bar(w)), 
     pch=20, col="red", cex = 2, cex.lab = 1.5, cex.main = 2.5,
     main = paste("p0 = ", p0, "and s = ", (1 - (w2/w1))))
    
    # 2. change in allele frequency over time
plot(x = 1:n, y = p, 
     xlab="generations", 
	 ylab="Allele frequency (p)", 
	 pch = 20, col = "red", cex.lab = 1.5)
		
	# 3. plot of p[t+1] vs p[t]
p.1 <- p[-n]
p.2 <- p[-1]

plot(p.2 ~ p.1, 
     xlab = expression(p[t]),
	 ylab = expression(p[t+1]), 
	 pch = 20, col = "red", cex = 2, cex.lab = 1.5)
		
# 4. plot of allele frequency change
plot(x = 2:n, y = delta_p[-1],
	    xlab = "generation",
	    ylab= expression(paste(Delta,"p")), 
	    pch = 20, col = "red", cex = 2, cex.lab = 1.5)
}
```

## Let's see what this does.

```{r}
haploid.selection(p0 = 0.0001, w1 = 1, w2 = 0.987, n = 1000)
```

## Stochastic simulations

- Probably the real power for your computational skills comes from performing stochastic simulations.
- That is adding some sources of random variation at various places in your model, and allowing it to *propogate* and influence your outcomes.

## Is it really random?
- Computers can not do true random numbers.
- Instead they use *pseudo-random* number generation.
- The details of how they do it, don't matter at the moment.
- What does matter is the effect it has.

## Is it really random?
- try running this code

```{r}
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
```

## Is it really random?
Now try it again, but let's seed the *seed* for the random number generator 

```{r}
set.seed(720)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
```

or 
```{r}
set.seed(720)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
set.seed(720)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
set.seed(720)
x <- rnorm(1000, mean = 5, sd = 1)
mean(x)
```

## Is it really random?
- No, but as long as we are aware of it, this can be very useful to check our work.
- If you don't specifically set the seed for random number generation, it defaults to the current time and date.


## Numerical stochastic simulations, the basics.

At the heart of stochastic simulations, is needing some sort of probability distribution to simulate from. The easiest one of course is the *uniform distribution*. The idea is to take random draws from this distribution upon repeated sampling. The set of functions we will use all start with lower case *r*, for random, like `rnorm()`, `runif`, `rbinom()`, etc...

## `runif`

- Let's start with generating a single random number from a uniform distribution on [0,1]

```{r}
runif(n = 1, min = 0, max = 1) 
```
- the rNameOfDist functions generate random numbers. 
- min sets lowest, max sets highest possible value, n is the number of draws from this distribution. 
- We can actually use the `runif` to generate random draws from all other distributions if we wanted to, but it is unnecessary here.

## `runif()`
If we wanted 1000 such numbers we could use a for loop, or the replicate() in R. However the easier way would be to ask for 1000 numbers with the n=1000 argument.

```{r}
ru1 <- runif(n = 10000, min = 0, max = 1)
length(ru1)
head(ru1)
tail(ru1)
```

- If I plotted a histogram of this data, what should it look like (at least theoretically)?

## 
```{r}
par(mfrow = c(1,1))
hist(ru1, freq = F)
curve(dunif(x, 0, 1), 0, 1, 
      add = T, col = "red", lwd = 2)
```

With the theoretical uniform distribution on [1,1] in red

## simulating from a normal distribution
- If we wanted to look at 100 draws from a normal distribution with mean =5 and sd=2
- $x \sim N(\mu = 5, \sigma = 2)$

```{r}
random.normal.100 <- rnorm(n = 100, mean = 5,sd = 2) 
par(mfrow=c(3,1))  
plot(random.normal.100)
boxplot(random.normal.100)
hist(random.normal.100)
```

- repeat this simulation a few times to confirm it is changing...

## More efficient random sampling using replicate
- Say I was doing this to get a sense of what would happen in a particular experiment with 100 samples. I may want to repeat this 10 times. How might I do this efficiently?

## More efficient random sampling using replicate

```{r}
random.normal.100.rep <- replicate(n = 10, 
                                   rnorm(100, 5, 2))


par(mfrow=c(4,4))
apply(X=random.normal.100.rep, 
      MARGIN=2, FUN=hist) 

apply(X=random.normal.100.rep, MARGIN=2, FUN=mean)

apply(random.normal.100.rep, 2, sd)
```

## 
the advantage of this approach is you can also just do

```{r}
summary(random.normal.100.rep)
```

## monte carlo methods
- This is an example of a very simple monte carlo simulation
- Let's use this to do something a bit more interesting, simulate from a regression model.
- $Y \sim N(\mu = a + b*x, \sigma)$
- We will make the slope $b = 0.7$, the intercept $a= 5$ and residual variation$\sigma = 2$
```{r}
par(mfrow=c(1,1))
a = 5 # intercept
b = 0.7 # slope
x <- seq(2,20) # values of our predictor "x"

y_fixed <- a + b*x # we are expressing the relationship between y and x as a linear model. In this case we are generating the data using such a model.

plot(y_fixed ~ x, main= "Deterministic Component of the model") # A linear model 
abline(a=5, b=0.7)
```

## add in stochastic component now
```{r}
y.sim.1 <- rnorm(length(x), mean = y_fixed, sd = 2)
plot(y.sim.1 ~ x, pch = 20)
abline(a = 5, b = 0.7, col = "red") # Expected relationship based on the parameters we used.

y.sim.1.lm <- lm(y.sim.1 ~ x) # fit a regression with simulated data
abline(reg = y.sim.1.lm, lty = 2, col = "blue") # estimated values based on simulated data.
```


## All important `sample()` function.
-Sometimes we don't want to sample from a probability distribution, but for discrete categories (say number of A, C, T and G in a sequence).
- The all powerful `sample()` is the workhorse function and is incredibly powerful for this!

## sample function in action.
- Say I wanted to generate a random sequence with 1000 bp, with no GC bias.

```{r}
seq1_no_bias <- sample(c("A","C","G", "T"), 
                       size = 100000, replace = TRUE)

length(seq1_no_bias)
head(seq1_no_bias)
```
- `replace = TRUE` means it can repeatedly draw from the letters ACGT, otherwise it could only use each once (for a maximum of 4 draws)

##
- Now we want to convert this to a single sequence.
```{r}
seq1 <- paste(seq1_no_bias, sep = "", collapse = "")
nchar(seq1)

x <- gregexpr("AACTTTT", seq1, fixed = T, useBytes = T)
unlist(x)
```

## with some GC bias

- Say our sequence simulation is supposed to be from *Drosophila* with a 60:40 GC:AT bias. We can just add in the prob argument.

```{r}
seq2_60GCbias <- paste(sample(c("A","C","G", "T"), 
                       size = 100000, prob = c(20,30,30,20),
                       replace = TRUE),
                       sep = "", collapse = "")

nchar(seq2_60GCbias)


y <- gregexpr("AACTTTT", seq2_60GCbias, fixed = T, useBytes = T)
unlist(y)

```
- How would you check?
