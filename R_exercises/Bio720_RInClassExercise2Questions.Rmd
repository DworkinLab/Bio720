---
title: "Bio720 R In Class Exercise 2"
author: "Ian Dworkin"
date: "October 24, 2016"
---

## for loops and the apply family of functions
This past week for screencasts and exercies, you learned a bit about how to use `for` loops and `apply` family of functions. Now we are going to do some in class practice and extend your understanding of how they work. In case you want some alternative tutorials [here](https://www.datacamp.com/community/tutorials/tutorial-on-loops-in-r#gs.FgFVHlY) is one that goes into more detail.

1 - What happens to `x` for each of these functions after you run them?

  ```{r}
  x <- 1

  for (i in 1:9) {
      x <- x + 1
      print(x)
  }

  x
  ```

  **VS**

  ```{r}
  rm(x)

  countFun <-function(x)
  {

    for (i in 1:10) {
      x <- x + 1
      print(x)
  }}

  countFun(1)
  x
  ```

  Why do these behave differently?


2 - Write a for loop that generates a vector which is the square of all integers from 1 to 10000. Make this all happen within the loop. i.e. We are going to use the `system.time()` function to monitor how long it takes.

  *Note: to use system time the for loop may need to be on one line*

  ```{r}
  # initialize a vector of length 1
  x <- NA
  system.time( YOUR FOR LOOP HERE)
  ```

3 - Now do the same thing but *pre-allocate* the vector `x` to store the 10000 values, *before* running the for loop.

```{r}
# initialize a vector of length 1
x <- rep(NA, 10000)

#system.time( YOUR FOR LOOP HERE)
```

  Which runs faster? Please explain why?

4 - Can you think of code that will be even faster?

  Why is this faster?

5 - So what is the lesson learned from this?

6 - Compare the following pieces of code for speed (you can wrap this in `system.time()`)

  ```{r}
  n <- 10000 # just run this once, each time you change n

  rm(x)
  system.time(x <- replicate(n = n, expr = rnorm(1, mean = 5, sd = 5)))
  ```

  **VS**

  ```{r}
  x <- rep(NA, n)
  system.time(for (i in 1:n) x[i] <- rnorm(1, mean = 5, sd = 5))
  ```

  Repeat each of these 5 times, and write down how long they take. Now repeat this for `n = 100000` iterations. Repeat for `n = 1000000`

  Is there a difference in speed? Can you explain why?

7 -  Can you think of a faster way to generate the random numbers?

## Running a power analysis.

In statistics, we often want to check (before doing an experiment) how likely we will be able to detect "an effect". This is true whether we are doing RNAseq, or a simple t-test. A tests statistical power is a function of three things. First, the magnitude of the observed effect (i.e. does your experiment have a big effect on gene expression or really small subtle effects). Second the amount of variation within each treatment group (if what you measure is really noisy, it will make it more difficult to get accurate estimates) and of course sample size. So when statistically oriented researchers are testing new methods, or just planning experiments, they will often use simulations to perform power analyses.  These require repeating the same simulations over and over again and checking results against some expectation or some hypothetical threshold (i.e. statistical significance is something some researchers care about... although you should focus on magnitude of effect size and confidence intervals... but that is another conversation).

Here is an example of a very simple simulation, which generates a linear relationship between two variables (the dependent variable x and the response variable y), simulates values of x based on this relationship and the amount of variation (noise) and then fits a linear regression and extracts the p-value associated with the slope of the relationship.

```{r}
rm(list=ls())

# sample size, n
n <- 20

# intercept, a
a = 3

# slope, b
b = 0.25

# independent/explanatory variable
x <- rnorm( n = n, mean = 10, sd = 2)

# response/dependent variable
y <- rnorm(n = length(x), mean = a + b*x, sd = 1 )

plot(y ~ x, pch = 20, cex = 1.5)

# use the `lm` function to fit a linear model (including  regression)
mod_1 <- lm(y ~ x)

summary(mod_1) # just to look at.

p_val <- summary(mod_1)$coef[2,4]
p_val
```

8 - How would you take this idea and create a vector that stores the p_values from these simulations, and repeat the simulation 1000 times using a for loop? Then use this vector to find out what proportion of p-values are less than 0.05.

9 -  How would you do the same thing as in question 9 but by writing a function and using `replicate`?

Why are the results from question 8 and 9 not the same?

10 - Say you wanted to see what would happened if you varied the sample size from n = 10 to n = 100 or varied the slope from 0 to 0.5? How would you do this using both approaches from questions 9 and 10 (you may need to use nested for loops).
